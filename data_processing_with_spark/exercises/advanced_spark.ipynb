{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757eee14",
   "metadata": {},
   "source": [
    "## Spark Session Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c31784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Advanced Spark\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5b740",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- listing_url: string (nullable = true)\n",
      " |-- scrape_id: long (nullable = true)\n",
      " |-- last_scraped: timestamp (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- neighborhood_overview: string (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- host_id: integer (nullable = true)\n",
      " |-- host_url: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- host_since: timestamp (nullable = true)\n",
      " |-- host_location: string (nullable = true)\n",
      " |-- host_about: string (nullable = true)\n",
      " |-- host_response_time: string (nullable = true)\n",
      " |-- host_response_rate: string (nullable = true)\n",
      " |-- host_acceptance_rate: string (nullable = true)\n",
      " |-- host_is_superhost: string (nullable = true)\n",
      " |-- host_thumbnail_url: string (nullable = true)\n",
      " |-- host_picture_url: string (nullable = true)\n",
      " |-- host_neighbourhood: string (nullable = true)\n",
      " |-- host_listings_count: integer (nullable = true)\n",
      " |-- host_total_listings_count: integer (nullable = true)\n",
      " |-- host_verifications: string (nullable = true)\n",
      " |-- host_has_profile_pic: string (nullable = true)\n",
      " |-- host_identity_verified: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- neighbourhood_cleansed: string (nullable = true)\n",
      " |-- neighbourhood_group_cleansed: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- property_type: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- accommodates: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- bathrooms_text: string (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- beds: integer (nullable = true)\n",
      " |-- amenities: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: integer (nullable = true)\n",
      " |-- maximum_nights: integer (nullable = true)\n",
      " |-- minimum_minimum_nights: integer (nullable = true)\n",
      " |-- maximum_minimum_nights: integer (nullable = true)\n",
      " |-- minimum_maximum_nights: integer (nullable = true)\n",
      " |-- maximum_maximum_nights: integer (nullable = true)\n",
      " |-- minimum_nights_avg_ntm: double (nullable = true)\n",
      " |-- maximum_nights_avg_ntm: double (nullable = true)\n",
      " |-- calendar_updated: string (nullable = true)\n",
      " |-- has_availability: string (nullable = true)\n",
      " |-- availability_30: integer (nullable = true)\n",
      " |-- availability_60: integer (nullable = true)\n",
      " |-- availability_90: integer (nullable = true)\n",
      " |-- availability_365: integer (nullable = true)\n",
      " |-- calendar_last_scraped: timestamp (nullable = true)\n",
      " |-- number_of_reviews: integer (nullable = true)\n",
      " |-- number_of_reviews_ltm: integer (nullable = true)\n",
      " |-- number_of_reviews_l30d: integer (nullable = true)\n",
      " |-- availability_eoy: integer (nullable = true)\n",
      " |-- number_of_reviews_ly: integer (nullable = true)\n",
      " |-- estimated_occupancy_l365d: integer (nullable = true)\n",
      " |-- estimated_revenue_l365d: integer (nullable = true)\n",
      " |-- first_review: timestamp (nullable = true)\n",
      " |-- last_review: timestamp (nullable = true)\n",
      " |-- review_scores_rating: double (nullable = true)\n",
      " |-- review_scores_accuracy: double (nullable = true)\n",
      " |-- review_scores_cleanliness: double (nullable = true)\n",
      " |-- review_scores_checkin: double (nullable = true)\n",
      " |-- review_scores_communication: double (nullable = true)\n",
      " |-- review_scores_location: double (nullable = true)\n",
      " |-- review_scores_value: double (nullable = true)\n",
      " |-- license: string (nullable = true)\n",
      " |-- instant_bookable: string (nullable = true)\n",
      " |-- calculated_host_listings_count: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_entire_homes: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_private_rooms: integer (nullable = true)\n",
      " |-- calculated_host_listings_count_shared_rooms: integer (nullable = true)\n",
      " |-- reviews_per_month: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "listings = spark.read.csv(\"../data/listings.csv.gz\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\", \n",
    "    quote='\"',\n",
    "    escape='\"', \n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\" \n",
    ")\n",
    "listings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb66d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- reviewer_id: integer (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews = spark.read.csv(\"../data/reviews.csv.gz\", \n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\",\",\n",
    "    quote='\"',\n",
    "    escape='\"',\n",
    "    multiLine=True,\n",
    "    mode=\"PERMISSIVE\"\n",
    ")\n",
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994c7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. For each listing compute string category depending on its price, and add it as a new column.\n",
    "# A category is defined in the following way:\n",
    "#\n",
    "# * price < 50 -> \"Budget\"\n",
    "# * 50 <= price < 150 -> \"Mid-range\"\n",
    "# * price >= 150 -> \"Luxury\"\n",
    "# \n",
    "# Only include listings where the price is not null.\n",
    "# Count the number of listings in each category\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "listings = listings.withColumn('price_numeric', regexp_replace('price', '[$,]', '').cast('float'))\n",
    "\n",
    "def categorize_price(price):\n",
    "    if price is None:\n",
    "        return 'Unknown'\n",
    "    elif price < 50:\n",
    "        return 'Budget'\n",
    "    elif 50 <= price < 150:\n",
    "        return 'Mid-range'\n",
    "    elif price >= 150:\n",
    "        return 'Luxury'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "\n",
    "categorize_price_udf = udf(categorize_price, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35dbb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_with_category = listings \\\n",
    "  .filter(listings.price_numeric.isNotNull()) \\\n",
    "  .withColumn(\n",
    "    'price_category',\n",
    "    categorize_price_udf(listings.price_numeric)\n",
    "  ) \\\n",
    "  .groupBy('price_category') \\\n",
    "  .count() \\\n",
    "  .orderBy('count', ascending=False) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de7e4540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. In this task you will need to compute a santiment score per review, and then an average sentiment score per listing.\n",
    "# A santiment score indicates how \"positive\" or \"negative\" a review is. The higher the score the more positive it is, and vice-versa.\n",
    "#\n",
    "# To compute a sentiment score per review compute the number of positive words in a review and subtract the number of negative\n",
    "# words in the same review (the list of words is already provided)\n",
    "#\n",
    "# To complete this task, compute a DataFrame that contains the following fields:\n",
    "# * name - the name of a listing\n",
    "# * average_sentiment - average sentiment of reviews computed using the algorithm described above\n",
    "\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "positive_words = ['good', 'great', 'excellent', 'amazing', 'fantastic', 'wonderful', 'pleasant', 'lovely', 'nice', 'enjoyed']\n",
    "negative_words = ['bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor', 'hate', 'unpleasant', 'dirty', 'noisy']\n",
    "\n",
    "def sentiment_score(comment):\n",
    "    if comment is None:\n",
    "        return 0.0\n",
    "    comment_lower = comment.lower()\n",
    "    score = 0\n",
    "\n",
    "    for word in positive_words:\n",
    "        if word in comment_lower:\n",
    "            score += 1\n",
    "\n",
    "    for word in negative_words:\n",
    "        if word in comment_lower:\n",
    "            score -= 1\n",
    "    return float(score)\n",
    "\n",
    "sentiment_score_udf = udf(sentiment_score, FloatType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "034c285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 2.0\n"
     ]
    }
   ],
   "source": [
    "test_comment = \"This place was great and wonderful!\"\n",
    "result = sentiment_score(test_comment)\n",
    "print(f\"Result: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ded15e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- listing_id: long (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- reviewer_id: integer (nullable = true)\n",
      " |-- reviewer_name: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_with_sentiment = reviews \\\n",
    "  .withColumn(\n",
    "    'sentiment_score',\n",
    "    sentiment_score_udf(reviews.comments)\n",
    "  )\n",
    "\n",
    "listings \\\n",
    "   .join(reviews_with_sentiment, listings.id == reviews.listing_id, 'inner') \\\n",
    "   .groupBy('listing_id', 'name') \\\n",
    "   .agg(\n",
    "      avg('sentiment_score').alias('average_sentiment')\n",
    "   ) \\\n",
    "   .orderBy('average_sentiment', ascending=False) \\\n",
    "   .select('listing_id', 'name', 'average_sentiment') \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd7699",
   "metadata": {},
   "source": [
    "### Alternate way as udf function throwing pickling error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6cfc0f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------------+-----------+-------------+--------------------+---------------+\n",
      "|listing_id|       id|               date|reviewer_id|reviewer_name|            comments|sentiment_score|\n",
      "+----------+---------+-------------------+-----------+-------------+--------------------+---------------+\n",
      "|     13913|    80770|2010-08-18 00:00:00|     177109|      Michael|My girlfriend and...|            2.0|\n",
      "|     13913|   367568|2011-07-11 00:00:00|   19835707|      Mathias|Alina was a reall...|            1.0|\n",
      "|     13913|   529579|2011-09-13 00:00:00|    1110304|      Kristin|Alina is an amazi...|            1.0|\n",
      "|     13913|   595481|2011-10-03 00:00:00|    1216358|      Camilla|Alina's place is ...|            2.0|\n",
      "|     13913|   612947|2011-10-09 00:00:00|     490840|        Jorik|Nice location in ...|            2.0|\n",
      "|     13913|  4847959|2013-05-28 00:00:00|    6405442|         Vera|I'm very happy to...|            3.0|\n",
      "|     13913|  8142329|2013-10-17 00:00:00|    9195551|         Honi|I stayed with Ali...|            2.0|\n",
      "|     13913| 11876590|2014-04-17 00:00:00|    5194009|   Alessandro|Alina was a perfe...|            1.0|\n",
      "|     13913| 46669566|2015-09-12 00:00:00|   42970248|         Oleh|Alina's flat is e...|            2.0|\n",
      "|     13913| 64559033|2016-03-05 00:00:00|   45337884|           Mo|The House is a pi...|            0.0|\n",
      "|     13913|196153582|2017-09-22 00:00:00|   40946748|            A|Was great base fo...|            1.0|\n",
      "|     13913|261305314|2018-05-06 00:00:00|  106481379|       Daniel|Alina was an amaz...|            1.0|\n",
      "|     13913|277816069|2018-06-17 00:00:00|   31960932|      Belinda|Lovely relaxed pl...|            1.0|\n",
      "|     13913|451955791|2019-05-12 00:00:00|   58728173|      Charles|Alina's place is ...|            0.0|\n",
      "|     13913|467269212|2019-06-10 00:00:00|    2291517|       Andrew|Alina, was very q...|            0.0|\n",
      "|     13913|538005731|2019-09-29 00:00:00|    7253695|         Bart|Alina is an amazi...|            3.0|\n",
      "|     13913|539957261|2019-10-02 00:00:00|   45592945|         John|Alina is a very r...|            1.0|\n",
      "|     13913|543287825|2019-10-07 00:00:00|   28531625|       Philip|Felt at home - Al...|            1.0|\n",
      "|     13913|568976830|2019-11-25 00:00:00|   38999586|         Ania|Alinaâ€™s place is ...|            1.0|\n",
      "|     13913|609079783|2020-02-22 00:00:00|  336060662|       Samuel|Outstanding host....|            1.0|\n",
      "+----------+---------+-------------------+-----------+-------------+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, lower, lit\n",
    "\n",
    "positive_words = ['good', 'great', 'excellent', 'amazing', 'fantastic', 'wonderful', 'pleasant', 'lovely', 'nice', 'enjoyed']\n",
    "negative_words = ['bad', 'terrible', 'awful', 'horrible', 'disappointing', 'poor', 'hate', 'unpleasant', 'dirty', 'noisy']\n",
    "\n",
    "# Create individual patterns for each word\n",
    "positive_score = lit(0)\n",
    "for word in positive_words:\n",
    "    positive_score = positive_score + when(lower(col('comments')).rlike(f'\\\\b{word}\\\\b'), 1).otherwise(0)\n",
    "\n",
    "negative_score = lit(0)\n",
    "for word in negative_words:\n",
    "    negative_score = negative_score + when(lower(col('comments')).rlike(f'\\\\b{word}\\\\b'), 1).otherwise(0)\n",
    "\n",
    "reviews_with_sentiment = reviews.limit(20) \\\n",
    "  .withColumn('sentiment_score', \n",
    "              when(col('comments').isNull(), lit(0.0))\n",
    "              .otherwise((positive_score - negative_score).cast('float')))\n",
    "\n",
    "reviews_with_sentiment.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694dd8c",
   "metadata": {},
   "source": [
    "### Using SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "feb3fb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+-------------+\n",
      "|        listing_id|average_comment_length|reviews_count|\n",
      "+------------------+----------------------+-------------+\n",
      "|618608352812465378|    1300.1666666666667|            6|\n",
      "|          28508447|    1089.3333333333333|            6|\n",
      "|627425975703032358|     951.7777777777778|            9|\n",
      "|           2197681|                 939.2|            5|\n",
      "|          13891813|                 905.0|            5|\n",
      "|            979753|     893.9230769230769|           13|\n",
      "|630150178279666225|     890.7272727272727|           11|\n",
      "|           8856894|     890.1666666666666|            6|\n",
      "|          29469389|                 885.0|            6|\n",
      "|          22524075|                 885.0|            5|\n",
      "|           5555679|     878.7169811320755|          106|\n",
      "|          33385444|                 848.0|            5|\n",
      "|            565214|     834.0833333333334|           12|\n",
      "|          53493254|                 831.0|            7|\n",
      "|          12646480|                 819.6|            5|\n",
      "|          17997858|               816.875|            8|\n",
      "|           8574525|     813.6666666666666|            6|\n",
      "|          38664252|     805.8333333333334|            6|\n",
      "|          16308170|     799.6666666666666|            6|\n",
      "|546424544012965343|               772.625|            8|\n",
      "+------------------+----------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Rewrite the following code from the previous exercise using SparkSQL:\n",
    "#\n",
    "# ```\n",
    "# from pyspark.sql.functions import length, avg, count\n",
    "# \n",
    "# reviews_with_comment_length = reviews.withColumn('comment_length', length('comments'))\n",
    "# reviews_with_comment_length \\\n",
    "#   .join(listings, reviews_with_comment_length.listing_id == listings.id, 'inner') \\\n",
    "#   .groupBy('listing_id').agg(\n",
    "#       avg(reviews_with_comment_length.comment_length).alias('average_comment_length'),\n",
    "#       count(reviews_with_comment_length.id).alias('reviews_count')\n",
    "#   ) \\\n",
    "#   .filter('reviews_count >= 5') \\\n",
    "#   .orderBy('average_comment_length', ascending=False) \\\n",
    "#   .show()\n",
    "# ```\n",
    "# This was a solution for the the task:\n",
    "#\n",
    "# \"Get top five listings with the highest average review comment length. Only return listings with at least 5 reviews\"\n",
    "\n",
    "reviews.createOrReplaceTempView(\"reviews\")\n",
    "listings.createOrReplaceTempView(\"listings\")\n",
    "\n",
    "# Write the SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT\n",
    "  r.listing_id,\n",
    "  AVG(LENGTH(r.comments)) AS average_comment_length,\n",
    "  COUNT(r.id) AS reviews_count\n",
    "FROM\n",
    "  reviews r\n",
    "JOIN\n",
    "  listings l\n",
    "  ON r.listing_id = l.id\n",
    "GROUP BY\n",
    "  r.listing_id\n",
    "HAVING\n",
    "  COUNT(r.id) >= 5\n",
    "ORDER BY\n",
    "  average_comment_length DESC\n",
    "\"\"\"\n",
    "\n",
    "spark \\\n",
    "  .sql(sql_query) \\\n",
    "  .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
