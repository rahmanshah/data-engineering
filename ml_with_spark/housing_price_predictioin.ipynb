{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "154f6ee4",
   "metadata": {},
   "source": [
    "#### Downloadind data from kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460922b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"harlfoxem/housesalesprediction\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e00c90",
   "metadata": {},
   "source": [
    "#### Initializing Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .appName('House price prediction') \\\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6334328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- bedrooms: integer (nullable = true)\n",
      " |-- bathrooms: double (nullable = true)\n",
      " |-- sqft_living: integer (nullable = true)\n",
      " |-- sqft_lot: integer (nullable = true)\n",
      " |-- floors: double (nullable = true)\n",
      " |-- waterfront: integer (nullable = true)\n",
      " |-- view: integer (nullable = true)\n",
      " |-- condition: integer (nullable = true)\n",
      " |-- grade: integer (nullable = true)\n",
      " |-- sqft_above: integer (nullable = true)\n",
      " |-- sqft_basement: integer (nullable = true)\n",
      " |-- yr_built: integer (nullable = true)\n",
      " |-- yr_renovated: integer (nullable = true)\n",
      " |-- zipcode: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- sqft_living15: integer (nullable = true)\n",
      " |-- sqft_lot15: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = spark.read.csv('data/kc_house_data.csv', header=True, inferSchema=True)\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59c50c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|        id|           date|   price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|    lat|    long|sqft_living15|sqft_lot15|\n",
      "+----------+---------------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "|7129300520|20141013T000000|221900.0|       3|      1.0|       1180|    5650|   1.0|         0|   0|        3|    7|      1180|            0|    1955|           0|  98178|47.5112|-122.257|         1340|      5650|\n",
      "|6414100192|20141209T000000|538000.0|       3|     2.25|       2570|    7242|   2.0|         0|   0|        3|    7|      2170|          400|    1951|        1991|  98125| 47.721|-122.319|         1690|      7639|\n",
      "|5631500400|20150225T000000|180000.0|       2|      1.0|        770|   10000|   1.0|         0|   0|        3|    6|       770|            0|    1933|           0|  98028|47.7379|-122.233|         2720|      8062|\n",
      "|2487200875|20141209T000000|604000.0|       4|      3.0|       1960|    5000|   1.0|         0|   0|        5|    7|      1050|          910|    1965|           0|  98136|47.5208|-122.393|         1360|      5000|\n",
      "|1954400510|20150218T000000|510000.0|       3|      2.0|       1680|    8080|   1.0|         0|   0|        3|    8|      1680|            0|    1987|           0|  98074|47.6168|-122.045|         1800|      7503|\n",
      "+----------+---------------+--------+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+-------+--------+-------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f4b15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'date',\n",
       " 'price',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b9d5db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb59c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+---+----+-------------+----------+\n",
      "| id|date|price|bedrooms|bathrooms|sqft_living|sqft_lot|floors|waterfront|view|condition|grade|sqft_above|sqft_basement|yr_built|yr_renovated|zipcode|lat|long|sqft_living15|sqft_lot15|\n",
      "+---+----+-----+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+---+----+-------------+----------+\n",
      "|  0|   0|    0|       0|        0|          0|       0|     0|         0|   0|        0|    0|         0|            0|       0|           0|      0|  0|   0|            0|         0|\n",
      "+---+----+-----+--------+---------+-----------+--------+------+----------+----+---------+-----+----------+-------------+--------+------------+-------+---+----+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "data \\\n",
    "  .select([F.count(F.when(F.col(c).isNull(), 1)).alias(c) for c in data.columns]) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae76be",
   "metadata": {},
   "source": [
    "#### Splitting the dataset to train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8974437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  17349\n",
      "Test size:  4264\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)\n",
    "print(\"Train size: \", train_data.count())\n",
    "print(\"Test size: \", test_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26c95841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4205aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_lot',\n",
       " 'floors',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated',\n",
       " 'zipcode',\n",
       " 'lat',\n",
       " 'long',\n",
       " 'sqft_living15',\n",
       " 'sqft_lot15']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select numerical columns (excluding the price)\n",
    "numerical_columns = [col for col, dtype in data.dtypes if dtype in ('int', 'double') and col != 'price'] \n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57851544",
   "metadata": {},
   "source": [
    "#### Date preparation, feature vector creation, Linear Regression model initialization and train a model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54180e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Create feature vectors\n",
    "assembler = VectorAssembler(inputCols=numerical_columns, outputCol='features')\n",
    "assembled_data = assembler.transform(data)\n",
    "\n",
    "# Prepare the dataset with features and label\n",
    "final_data = assembled_data.select('features', 'price')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dd09187",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/18 19:46:49 WARN Instrumentation: [55bea5b4] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "lr = LinearRegression(featuresCol='features', labelCol='price')\n",
    "lr_model = lr.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4e0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
