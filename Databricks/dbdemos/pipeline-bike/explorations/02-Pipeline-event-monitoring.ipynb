{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "19a06679-c1c7-42b8-a3e9-e956c1bfafb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Explore data quality metrics from the pipeline event log\n",
    "\n",
    "Each pipeline can be configured to save out the metrics to a table in Unity Catalog. From this table we can see what is happening and the quality of the data passing through it.\n",
    "You can leverage the expecations directly as a SQL table with Databricks SQL to track your expectation metrics and send alerts as required. \n",
    "This notebook extracts and analyses expectation metrics to build such KPIS.\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=796524194907820&notebook=%2Fexplorations%2F02-Pipeline-event-monitoring&demo_name=pipeline-bike&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fpipeline-bike%2Fexplorations%2F02-Pipeline-event-monitoring&version=1\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c88e66f-7c1f-48dc-ae71-8e2c1d85856b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Your event log table is now available as a Table within your schema!\n",
    "This is simply set as an option in your pipeline configuration menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cc3df6d-6933-42a3-ab5d-8e91354f342d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  main.dbdemos_pipeline_bike.pipeline_bike_event_logs\n",
    "limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "300514ee-ae3f-468d-bd71-ac7fe29688cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The `details` column contains metadata about each Event sent to the Event Log in a JSON blob. Using `parse_json` and the `VARIANT` data type we can explore it as if it was an object. There are different fields depending on what type of Event it is. Some examples include:\n",
    "* `user_action` Events occur when taking actions like creating the pipeline\n",
    "* `flow_definition` Events occur when a pipeline is deployed or updated and have lineage, schema, and execution plan information\n",
    "  * `output_dataset` and `input_datasets` - output table/view and its upstream table(s)/view(s)\n",
    "  * `flow_type` - whether this is a complete or append flow\n",
    "  * `explain_text` - the Spark explain plan\n",
    "* `flow_progress` Events occur when a data flow starts running or finishes processing a batch of data\n",
    "  * `metrics` - currently contains `num_output_rows`\n",
    "  * `data_quality` - contains an array of the results of the data quality rules for this particular dataset\n",
    "    * `dropped_records`\n",
    "    * `expectations`\n",
    "      * `name`, `dataset`, `passed_records`, `failed_records`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "470e489a-ff92-4f7f-a160-3e3a79c01b5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  details:flow_definition.output_dataset,\n",
    "  details:flow_definition.input_datasets,\n",
    "  details:flow_definition.flow_type,\n",
    "  details:flow_definition.schema,\n",
    "  details:flow_definition\n",
    "FROM main.dbdemos_pipeline_bike.pipeline_bike_event_logs\n",
    "WHERE details:flow_definition IS NOT NULL\n",
    "ORDER BY timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c94bade6-f0c3-44e3-9ad7-358cd5580846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select\n",
    "  e.origin.update_id,\n",
    "  ex.value:name::string,\n",
    "  ex.value:dataset::string,\n",
    "  ex.value:passed_records::long as passed_records,\n",
    "  ex.value:failed_records::long as failed_records\n",
    "from\n",
    "  main.dbdemos_pipeline_bike.pipeline_bike_event_logs e,\n",
    "  lateral variant_explode(parse_json(e.details:flow_progress:data_quality:expectations:[ * ])) as ex\n",
    "where\n",
    "  e.event_type = \"flow_progress\"\n",
    "  and details:flow_progress:status = \"RUNNING\"\n",
    "  and details:flow_progress:data_quality:expectations IS NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39da914f-049a-46ad-8c33-f352a60938a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Tracking data quality as an AI/BI dashboard\n",
    "\n",
    "Let's leverage Databricks AI/BI dashboard to monitor our pipeline and data ingestion. \n",
    "\n",
    "- Open the <a  dbdemos-dashboard-id=\"data-quality\" href='/sql/dashboardsv3/01f0a99554a21eca84cf62cd2c8823b1' target=\"_blank\">Bike Rental Data Monitoring Dashboard</a> to track all your data quality, and add alerts based on your requirements.\n",
    "- Open the <a  dbdemos-dashboard-id=\"operational\" href='/sql/dashboardsv3/01f0a99554651cb280bc3da6714779ae' target=\"_blank\">Bike Rental Operational Pipeline Dashboard</a> to track all your pipeline event and cost!"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5317486578662997,
     "dataframes": [
      "_sqldf"
     ]
    }
   },
   "notebookName": "02-Pipeline-event-monitoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
